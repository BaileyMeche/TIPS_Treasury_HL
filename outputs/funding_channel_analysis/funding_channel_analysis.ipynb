{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07646712",
   "metadata": {},
   "source": [
    "# Funding Channel Analysis\n",
    "\n",
    "This notebook documents the weekly-frequency exercise linking TIPS-Treasury mispricing persistence to synthetic funding proxies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15510050",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "- `_data/mispricing_basis.csv` resampled to weekly averages.\n",
    "- `_output/mispricing_report.html` for benchmark persistence metrics and event windows.\n",
    "- `outputs/strategy3/concentration_metrics.csv` for tenor-level liquidity measures.\n",
    "- Synthetic funding proxies located in `inputs/funding_channels/`.\n",
    "- WRDS probe failed; see `_output/funding_channel_failure_log.json`.\n",
    "- Outputs saved to `outputs/funding_channel_analysis/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00731f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path('.')\n",
    "basis_df = pd.read_csv(ROOT / '_data' / 'mispricing_basis.csv', parse_dates=['date']).rename(columns={'tenor': 'tenor_bucket'})\n",
    "weekly_basis = basis_df.set_index('date').groupby('tenor_bucket')['basis'].resample('W-FRI').mean().reset_index()\n",
    "weekly_basis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41c8e79",
   "metadata": {},
   "source": [
    "### Rolling AR(1) computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 26\n",
    "records = []\n",
    "for tenor, grp in weekly_basis.groupby('tenor_bucket'):\n",
    "    grp = grp.sort_values('date').copy()\n",
    "    grp['basis_lag1'] = grp['basis'].shift(1)\n",
    "    for idx in range(WINDOW, len(grp)):\n",
    "        window = grp.iloc[idx-WINDOW+1:idx+1]\n",
    "        if window['basis_lag1'].isna().any():\n",
    "            continue\n",
    "        X = sm.add_constant(window['basis_lag1'])\n",
    "        model = sm.OLS(window['basis'], X).fit()\n",
    "        phi = model.params['basis_lag1']\n",
    "        hl = -np.log(2) / np.log(phi) if 0 < phi < 1 else np.nan\n",
    "        records.append({\n",
    "            'date': window['date'].iloc[-1],\n",
    "            'tenor_bucket': tenor,\n",
    "            'ar1_rolling': phi,\n",
    "            'half_life_rolling': hl,\n",
    "            'window_nobs': int(model.nobs)\n",
    "        })\n",
    "rolling_df = pd.DataFrame(records)\n",
    "rolling_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf8864",
   "metadata": {},
   "source": [
    "### Funding proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "funding_df = pd.read_csv(ROOT / 'inputs' / 'funding_channels' / 'cip_basis_series.csv', parse_dates=['date'])\n",
    "wedge_df = pd.read_csv(ROOT / 'inputs' / 'funding_channels' / 'money_market_wedge.csv', parse_dates=['date'])\n",
    "swap_df = pd.read_csv(ROOT / 'inputs' / 'funding_channels' / 'swap_spread_proxy.csv', parse_dates=['date'])\n",
    "funding_weekly = funding_df.merge(wedge_df, on='date', how='outer').merge(swap_df, on='date', how='outer').set_index('date').resample('W-FRI').mean().reset_index()\n",
    "funding_weekly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e367c",
   "metadata": {},
   "source": [
    "### Merge controls and compute Funding PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "liq_df = pd.read_csv(ROOT / 'outputs' / 'strategy3' / 'concentration_metrics.csv', parse_dates=['qdate']).rename(columns={'qdate': 'date'})\n",
    "liq_weekly = liq_df.set_index('date').groupby('tenor_bucket')[['liq_hhi','issue_conc_top3','issue_conc_top5','pubout','n_issues']].resample('W-FRI').mean().reset_index()\n",
    "agg_weekly = liq_df.set_index('date')[['liq_hhi','pubout','n_issues','issue_conc_top3','issue_conc_top5']].resample('W-FRI').agg({'liq_hhi':'mean','pubout':'sum','n_issues':'sum','issue_conc_top3':'mean','issue_conc_top5':'mean'}).reset_index()\n",
    "panel = rolling_df.merge(liq_weekly, on=['date','tenor_bucket'], how='left').merge(agg_weekly, on='date', how='left').merge(funding_weekly, on='date', how='left')\n",
    "fund_cols = ['CIP_basis_USDJPY','CIP_basis_EURUSD','RRP_bill_wedge','swap_spread_10y']\n",
    "valid = panel.dropna(subset=fund_cols).drop_duplicates(subset='date')\n",
    "scaler = StandardScaler()\n",
    "pca = PCA(n_components=1)\n",
    "valid['Funding_PC'] = pca.fit_transform(scaler.fit_transform(valid[fund_cols]))\n",
    "panel = panel.merge(valid[['date','Funding_PC']], on='date', how='left')\n",
    "panel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d5ce5",
   "metadata": {},
   "source": [
    "### Regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc5d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = ['liq_hhi','agg_liq_hhi','agg_pubout','agg_n_issues']\n",
    "reg_sample = panel.dropna(subset=['half_life_rolling'] + fund_cols + controls)\n",
    "reg_sample['quarter_end'] = reg_sample['date'].dt.is_quarter_end.astype(int)\n",
    "example = reg_sample[reg_sample['tenor_bucket']==10]\n",
    "X = sm.add_constant(example[fund_cols + controls + ['quarter_end']])\n",
    "model = sm.OLS(example['half_life_rolling'], X).fit()\n",
    "print(model.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bacce8",
   "metadata": {},
   "source": [
    "### Export artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009530ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel.to_csv('outputs/funding_channel_analysis/merged_funding_panel_preview.csv', index=False)\n",
    "panel.describe().to_csv('outputs/funding_channel_analysis/merged_funding_panel_descriptive.csv')\n",
    "print('Preview and descriptive stats saved.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
